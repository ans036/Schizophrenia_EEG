{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"anaconda-cloud":{},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7437293,"sourceType":"datasetVersion","datasetId":4328565},{"sourceId":8326186,"sourceType":"datasetVersion","datasetId":4945248}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyedflib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:52:53.608281Z","iopub.execute_input":"2025-03-27T04:52:53.609028Z","iopub.status.idle":"2025-03-27T04:53:02.256643Z","shell.execute_reply.started":"2025-03-27T04:52:53.608997Z","shell.execute_reply":"2025-03-27T04:53:02.255725Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyedflib in /opt/conda/lib/python3.10/site-packages (0.1.40)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from pyedflib) (1.26.4)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# %% [markdown]\n\"\"\"\n# ChronoNet-Inspired EEG Brain Map Classification (Merged .eea and .edf)\nThis script:\n- Reads EEG data from two sources: .eea files (e.g., from \"/kaggle/input/mhrc-dataset-data\") and .edf files (e.g., from \"/kaggle/input/schizophrenia\").\n- Computes PSD, Spectral Entropy (SE), and Differential Entropy (DE) features for four frequency bands (theta, alpha, beta, gamma).\n- Creates 2D brain maps (8×9) for each band.\n- Merges the two datasets according to your project logic.\n- Augments the data:\n    - For target class 1, each sample is augmented (n_augments=4 per sample).\n    - Then, class 0 is augmented until the final number of class 0 samples is twice that of class 1.\n- Stacks the three feature types for each band into ChronoNet‐compatible inputs (each sample becomes a sequence of 4 time steps, each with 216 features).\n- Builds and trains a ChronoNet‐inspired model (using parallel 1D conv layers with varying kernel sizes and GRU layers).\n- Plots training curves and evaluation metrics.\n\"\"\"\n\n# %% \nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport pyedflib\nfrom scipy.signal import welch\nfrom scipy.stats import entropy\nfrom zipfile import ZipFile\nfrom tensorflow.keras import layers, models, Model, Input\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom sklearn.model_selection import train_test_split\n\n# %% [markdown]\n\"\"\"\n## 1. Functions for Reading Files and Computing Features\nThese functions read .eea and .edf files, compute the PSD, SE, and DE features, and create a 2D brain map using a predefined channel-to-position map.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:02.258523Z","iopub.execute_input":"2025-03-27T04:53:02.258805Z","iopub.status.idle":"2025-03-27T04:53:02.267556Z","shell.execute_reply.started":"2025-03-27T04:53:02.258779Z","shell.execute_reply":"2025-03-27T04:53:02.266675Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\n## 1. Functions for Reading Files and Computing Features\\nThese functions read .eea and .edf files, compute the PSD, SE, and DE features, and create a 2D brain map using a predefined channel-to-position map.\\n'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def read_eea_file(eea_file, num_channels=16, samples_per_channel=7680):\n    with open(eea_file, 'r') as f:\n        data = f.read().split('\\n')\n    data = [float(item) for item in data if item]\n    return np.reshape(data, (num_channels, samples_per_channel))\n\ndef compute_psd(signal, fs=128, nperseg=256):\n    freqs, psd = welch(signal, fs=fs, nperseg=nperseg)\n    return freqs, psd\n\ndef compute_se(psd, freqs, bands):\n    se = []\n    for band in bands:\n        band_mask = (freqs >= band[0]) & (freqs <= band[1])\n        band_psd = psd[band_mask]\n        total = np.sum(band_psd)\n        if total != 0:\n            band_psd = band_psd / total\n        se.append(entropy(band_psd))\n    return se\n\ndef compute_de(psd, freqs, bands):\n    de = []\n    for band in bands:\n        band_mask = (freqs >= band[0]) & (freqs <= band[1])\n        band_psd = psd[band_mask]\n        band_de = np.sum(np.log(band_psd + 1e-10) * band_psd)\n        de.append(band_de)\n    return de\n\ndef extract_features(signal, fs=128, bands=None):\n    if bands is None:\n        bands = [(4,8), (8,12), (13,30), (30,40)]  # theta, alpha, beta, gamma\n    freqs, psd = compute_psd(signal, fs)\n    psd_features = np.array([np.trapz(psd[(freqs >= b[0]) & (freqs <= b[1])]) for b in bands])\n    se_features = compute_se(psd, freqs, bands)\n    de_features = compute_de(psd, freqs, bands)\n    return psd_features, se_features, de_features\n\ndef create_brain_map_per_band(feature_data, channels, position_map):\n    \"\"\"\n    feature_data: 1D array with one feature per channel for a given band.\n    \"\"\"\n    brain_map = np.zeros((8, 9))\n    for ch in channels:\n        if ch in position_map:\n            pos = position_map[ch]\n            x, y = map(int, pos.split(','))\n            brain_map[x, y] = feature_data[channels.index(ch)]\n    return brain_map\n\n# %% [markdown]\n\"\"\"\n### Reading .edf Files\nWe use pyedflib to read .edf files. Channels 'Fp1', 'Fz', and 'Fp2' are dropped if present.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:02.268767Z","iopub.execute_input":"2025-03-27T04:53:02.269065Z","iopub.status.idle":"2025-03-27T04:53:02.282635Z","shell.execute_reply.started":"2025-03-27T04:53:02.269044Z","shell.execute_reply":"2025-03-27T04:53:02.281837Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"\"\\n### Reading .edf Files\\nWe use pyedflib to read .edf files. Channels 'Fp1', 'Fz', and 'Fp2' are dropped if present.\\n\""},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def read_edf(edf_file):\n    f = pyedflib.EdfReader(edf_file)\n    n = f.signals_in_file\n    signal_labels = f.getSignalLabels()\n    sigbufs = np.zeros((n, f.getNSamples()[0]))\n    for i in range(n):\n        sigbufs[i, :] = f.readSignal(i)\n    df = pd.DataFrame(sigbufs.transpose(), columns=signal_labels)\n    for ch in ['Fp1', 'Fz', 'Fp2']:\n        if ch in df.columns:\n            df = df.drop(columns=[ch])\n    return df\n\n# %% [markdown]\n\"\"\"\n### Processing Functions for .eea and .edf Files\nFor .eea files, we process files from two subdirectories (with labels 0 and 1) and create brain maps per band.\nFor .edf files, we label based on the filename prefix ('h' for class 0, 's' for class 1) and create one brain map per band.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:02.284833Z","iopub.execute_input":"2025-03-27T04:53:02.285433Z","iopub.status.idle":"2025-03-27T04:53:02.295702Z","shell.execute_reply.started":"2025-03-27T04:53:02.285405Z","shell.execute_reply":"2025-03-27T04:53:02.294776Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"\\n### Processing Functions for .eea and .edf Files\\nFor .eea files, we process files from two subdirectories (with labels 0 and 1) and create brain maps per band.\\nFor .edf files, we label based on the filename prefix ('h' for class 0, 's' for class 1) and create one brain map per band.\\n\""},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def process_eea_and_store_brain_maps(directory, channels, position_map, bands=[(4,8), (8,12), (13,30), (30,100)]):\n    all_psd_maps = []\n    all_se_maps = []\n    all_de_maps = []\n    labels = []\n    for subdir, label in [('SCZ-Dataset2-Normal', 0), ('SCZ-Dataset2-SCZ', 1)]:\n        subdir_path = os.path.join(directory, subdir)\n        for filename in os.listdir(subdir_path):\n            if filename.endswith(\".eea\"):\n                file_path = os.path.join(subdir_path, filename)\n                data_array = read_eea_file(file_path)\n                psd_per_channel = []\n                se_per_channel = []\n                de_per_channel = []\n                for ch in range(data_array.shape[0]):\n                    psd_feat, se_feat, de_feat = extract_features(data_array[ch, :], fs=128, bands=bands)\n                    psd_per_channel.append(psd_feat)\n                    se_per_channel.append(se_feat)\n                    de_per_channel.append(de_feat)\n                psd_per_band = np.transpose(np.array(psd_per_channel))  # (num_bands, num_channels)\n                se_per_band  = np.transpose(np.array(se_per_channel))\n                de_per_band  = np.transpose(np.array(de_per_channel))\n                psd_maps = np.array([create_brain_map_per_band(psd_per_band[i], channels, position_map) for i in range(len(bands))])\n                se_maps  = np.array([create_brain_map_per_band(se_per_band[i], channels, position_map) for i in range(len(bands))])\n                de_maps  = np.array([create_brain_map_per_band(de_per_band[i], channels, position_map) for i in range(len(bands))])\n                all_psd_maps.append(psd_maps)\n                all_se_maps.append(se_maps)\n                all_de_maps.append(de_maps)\n                labels.append(label)\n    return (np.array(all_psd_maps), np.array(all_se_maps), np.array(all_de_maps)), np.array(labels)\n\ndef process_and_store_brain_maps(directory, channels, position_map, bands=[(4,8), (8,12), (13,30), (30,100)]):\n    all_psd_maps = []\n    all_se_maps = []\n    all_de_maps = []\n    labels = []\n    for filename in os.listdir(directory):\n        if filename.endswith(\".edf\"):\n            if filename.startswith(\"h\"):\n                label = 0\n            elif filename.startswith(\"s\"):\n                label = 1\n            else:\n                continue\n            df = read_edf(os.path.join(directory, filename))\n            data_array = df[channels].values  # shape: (num_samples, num_channels)\n            psd_brain_maps_per_band = []\n            se_brain_maps_per_band = []\n            de_brain_maps_per_band = []\n            for ch in range(data_array.shape[1]):\n                psd, se, de = extract_features(data_array[:, ch], fs=256, bands=bands)\n                psd_brain_maps_per_band.append(psd)\n                se_brain_maps_per_band.append(se)\n                de_brain_maps_per_band.append(de)\n            trans_psd = np.transpose(np.array(psd_brain_maps_per_band))  # (num_bands, num_channels)\n            trans_se  = np.transpose(np.array(se_brain_maps_per_band))\n            trans_de  = np.transpose(np.array(de_brain_maps_per_band))\n            psd_maps = np.array([create_brain_map_per_band(trans_psd[i], channels, position_map) for i in range(len(bands))])\n            se_maps  = np.array([create_brain_map_per_band(trans_se[i], channels, position_map) for i in range(len(bands))])\n            de_maps  = np.array([create_brain_map_per_band(trans_de[i], channels, position_map) for i in range(len(bands))])\n            all_psd_maps.append(psd_maps)\n            all_se_maps.append(se_maps)\n            all_de_maps.append(de_maps)\n            labels.append(label)\n    return (np.array(all_psd_maps), np.array(all_se_maps), np.array(all_de_maps)), np.array(labels)\n\n# %% [markdown]\n\"\"\"\n## 2. Data Preparation: Merging .eea and .edf Datasets and Augmentation\nWe process .eea and .edf files from separate directories, merge the datasets, and then augment.\n- First, augment class 1 with n_augments=4 per sample.\n- Then, compute current class counts and determine how many additional class 0 samples are needed so that the final ratio of class1:class0 becomes 1:2.\n- Augment class 0 accordingly.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:02.297037Z","iopub.execute_input":"2025-03-27T04:53:02.297291Z","iopub.status.idle":"2025-03-27T04:53:02.316060Z","shell.execute_reply.started":"2025-03-27T04:53:02.297271Z","shell.execute_reply":"2025-03-27T04:53:02.315169Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\n## 2. Data Preparation: Merging .eea and .edf Datasets and Augmentation\\nWe process .eea and .edf files from separate directories, merge the datasets, and then augment.\\n- First, augment class 1 with n_augments=4 per sample.\\n- Then, compute current class counts and determine how many additional class 0 samples are needed so that the final ratio of class1:class0 becomes 1:2.\\n- Augment class 0 accordingly.\\n'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Define channels and electrode position map\nchannels = ['F7','F3','F4','F8','T3','C3','Cz','C4','T4','T5','P3','Pz','P4','T6','O1','O2']\nposition_map = {\n    'F7':'1,0', 'F3':'1,2', 'F4':'1,6', 'F8':'1,8',\n    'T3':'3,0', 'C3':'3,2', 'Cz':'3,4', 'C4':'3,6', 'T4':'3,8',\n    'T5':'5,0', 'P3':'5,2', 'Pz':'5,4', 'P4':'5,6', 'T6':'5,8',\n    'O1':'7,3', 'O2':'7,5'\n}\n\n# Process .eea files (e.g., from \"mhrc-dataset-data\")\neea_directory = \"/kaggle/input/mhrc-dataset-data\"\n(all_psd_maps_eea, all_se_maps_eea, all_de_maps_eea), labels_eea = process_eea_and_store_brain_maps(eea_directory, channels, position_map)\n\n# Process .edf files (e.g., from \"schizophrenia\")\nedf_directory = \"/kaggle/input/schizophrenia\"\n(all_psd_maps_edf, all_se_maps_edf, all_de_maps_edf), labels_edf = process_and_store_brain_maps(edf_directory, channels, position_map)\n\nprint(\"EEA dataset shapes (PSD,SE,DE):\", all_psd_maps_eea.shape, all_se_maps_eea.shape, all_de_maps_eea.shape)\nprint(\"EDF dataset shapes (PSD,SE,DE):\", all_psd_maps_edf.shape, all_se_maps_edf.shape, all_de_maps_edf.shape)\n\n# Merge the two datasets (order: EDF then EEA)\nmerged_psd_maps = np.concatenate([all_psd_maps_edf, all_psd_maps_eea], axis=0)\nmerged_se_maps  = np.concatenate([all_se_maps_edf, all_se_maps_eea], axis=0)\nmerged_de_maps  = np.concatenate([all_de_maps_edf, all_de_maps_eea], axis=0)\nmerged_labels   = np.concatenate([labels_edf, labels_eea], axis=0)\n\nprint(\"Merged PSD maps shape:\", merged_psd_maps.shape)\nprint(\"Merged Labels shape:\", merged_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:02.317179Z","iopub.execute_input":"2025-03-27T04:53:02.317450Z","iopub.status.idle":"2025-03-27T04:53:16.845203Z","shell.execute_reply.started":"2025-03-27T04:53:02.317430Z","shell.execute_reply":"2025-03-27T04:53:16.844240Z"}},"outputs":[{"name":"stdout","text":"EEA dataset shapes (PSD,SE,DE): (84, 4, 8, 9) (84, 4, 8, 9) (84, 4, 8, 9)\nEDF dataset shapes (PSD,SE,DE): (28, 4, 8, 9) (28, 4, 8, 9) (28, 4, 8, 9)\nMerged PSD maps shape: (112, 4, 8, 9)\nMerged Labels shape: (112,)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def augment_brain_maps_specific_class(brain_maps, labels, target_class, n_augments=4, random_seed=42):\n    np.random.seed(random_seed)\n    augmented_maps = []\n    augmented_labels = []\n    for i in range(len(labels)):\n        if labels[i] == target_class:\n            possible_indices = [j for j, lab in enumerate(labels) if lab == target_class and j != i]\n            for _ in range(n_augments):\n                if len(possible_indices) == 0:\n                    continue\n                j = np.random.choice(possible_indices)\n                alpha = np.random.rand()\n                new_sample = alpha * brain_maps[i] + (1 - alpha) * brain_maps[j]\n                augmented_maps.append(new_sample)\n                augmented_labels.append(target_class)\n    if len(augmented_maps) > 0:\n        augmented_maps = np.array(augmented_maps)\n        augmented_labels = np.array(augmented_labels)\n        brain_maps_aug = np.concatenate([brain_maps, augmented_maps], axis=0)\n        labels_aug = np.concatenate([labels, augmented_labels], axis=0)\n        return brain_maps_aug, labels_aug\n    else:\n        return brain_maps, labels\n\ndef augment_class_to_target(brain_maps, labels, target_class, additional_needed, random_seed=42):\n    np.random.seed(random_seed)\n    class_indices = [i for i, lab in enumerate(labels) if lab == target_class]\n    augmented_samples = []\n    for _ in range(additional_needed):\n        i, j = np.random.choice(class_indices, size=2, replace=True)\n        alpha = np.random.rand()\n        new_sample = alpha * brain_maps[i] + (1 - alpha) * brain_maps[j]\n        augmented_samples.append(new_sample)\n    if len(augmented_samples) > 0:\n        augmented_samples = np.array(augmented_samples)\n        new_labels = np.full((augmented_samples.shape[0],), target_class)\n        brain_maps_aug = np.concatenate([brain_maps, augmented_samples], axis=0)\n        labels_aug = np.concatenate([labels, new_labels], axis=0)\n        return brain_maps_aug, labels_aug\n    else:\n        return brain_maps, labels\n\n# First, augment target class 1 (n_augments=4 per sample) for each feature type.\nmerged_psd_maps_aug, merged_labels_aug = augment_brain_maps_specific_class(merged_psd_maps, merged_labels, target_class=1, n_augments=4)\nmerged_se_maps_aug, merged_labels_aug = augment_brain_maps_specific_class(merged_se_maps, merged_labels_aug, target_class=1, n_augments=4)\nmerged_de_maps_aug, merged_labels_aug = augment_brain_maps_specific_class(merged_de_maps, merged_labels_aug, target_class=1, n_augments=4)\n\n# Compute current counts.\ncount_class1 = np.sum(merged_labels_aug == 1)\ncount_class0 = np.sum(merged_labels_aug == 0)\ndesired_class0 = 2 * count_class1\nadditional_needed = desired_class0 - count_class0\nprint(\"After class 1 augmentation: Class0 =\", count_class0, \", Class1 =\", count_class1)\nprint(\"Additional class 0 samples needed for 1:2 ratio:\", additional_needed)\n\n# Augment class 0 if additional samples are needed.\nif additional_needed > 0:\n    merged_psd_maps_aug, merged_labels_aug = augment_class_to_target(merged_psd_maps_aug, merged_labels_aug, target_class=0, additional_needed=additional_needed, random_seed=42)\n    merged_se_maps_aug, merged_labels_aug = augment_class_to_target(merged_se_maps_aug, merged_labels_aug, target_class=0, additional_needed=additional_needed, random_seed=42)\n    merged_de_maps_aug, merged_labels_aug = augment_class_to_target(merged_de_maps_aug, merged_labels_aug, target_class=0, additional_needed=additional_needed, random_seed=42)\n\nprint(\"After augmentation, PSD maps shape:\", merged_psd_maps_aug.shape)\nprint(\"After augmentation, Labels shape:\", merged_labels_aug.shape)\n\n# %% [markdown]\n\"\"\"\n## 3. Stacking Feature Maps for ChronoNet Input\nFor each sample and each band (4 bands), the 8×9 brain maps (for PSD, SE, and DE) are flattened (72 elements each)\nand concatenated to form a 216-dimensional vector per band. The final input shape becomes (num_samples, 4, 216).\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.846432Z","iopub.execute_input":"2025-03-27T04:53:16.846702Z","iopub.status.idle":"2025-03-27T04:53:16.941108Z","shell.execute_reply.started":"2025-03-27T04:53:16.846681Z","shell.execute_reply":"2025-03-27T04:53:16.939798Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# First, augment target class 1 (n_augments=4 per sample) for each feature type.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m merged_psd_maps_aug, merged_labels_aug \u001b[38;5;241m=\u001b[39m augment_brain_maps_specific_class(merged_psd_maps, merged_labels, target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_augments\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m merged_se_maps_aug, merged_labels_aug \u001b[38;5;241m=\u001b[39m \u001b[43maugment_brain_maps_specific_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_se_maps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_labels_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_augments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m merged_de_maps_aug, merged_labels_aug \u001b[38;5;241m=\u001b[39m augment_brain_maps_specific_class(merged_de_maps, merged_labels_aug, target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_augments\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute current counts.\u001b[39;00m\n","Cell \u001b[0;32mIn[22], line 13\u001b[0m, in \u001b[0;36maugment_brain_maps_specific_class\u001b[0;34m(brain_maps, labels, target_class, n_augments, random_seed)\u001b[0m\n\u001b[1;32m     11\u001b[0m j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(possible_indices)\n\u001b[1;32m     12\u001b[0m alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand()\n\u001b[0;32m---> 13\u001b[0m new_sample \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m brain_maps[i] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m \u001b[43mbrain_maps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m augmented_maps\u001b[38;5;241m.\u001b[39mappend(new_sample)\n\u001b[1;32m     15\u001b[0m augmented_labels\u001b[38;5;241m.\u001b[39mappend(target_class)\n","\u001b[0;31mIndexError\u001b[0m: index 156 is out of bounds for axis 0 with size 112"],"ename":"IndexError","evalue":"index 156 is out of bounds for axis 0 with size 112","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"def stack_maps_for_chrononet(psd_maps, se_maps, de_maps):\n    num_samples, num_bands, h, w = psd_maps.shape\n    stacked = []\n    for i in range(num_samples):\n        sample_seq = []\n        for b in range(num_bands):\n            psd_flat = psd_maps[i, b].flatten()\n            se_flat  = se_maps[i, b].flatten()\n            de_flat  = de_maps[i, b].flatten()\n            combined = np.concatenate([psd_flat, se_flat, de_flat])  # 72 * 3 = 216\n            sample_seq.append(combined)\n        stacked.append(np.array(sample_seq))\n    return np.array(stacked)\n\nstacked_features = stack_maps_for_chrononet(merged_psd_maps_aug, merged_se_maps_aug, merged_de_maps_aug)\nprint(\"Stacked features shape (ChronoNet input):\", stacked_features.shape)\n\n# One-hot encode labels (2 classes)\nlabels_cat = to_categorical(merged_labels_aug, num_classes=2)\n\n# %% [markdown]\n\"\"\"\n## 4. Building a ChronoNet-Inspired Model\nThe model takes input of shape (4, 216) and uses parallel 1D convolution layers (with kernel sizes 2, 4, and 8).\nTheir outputs are concatenated, followed by another parallel convolution block, two GRU layers, dropout,\nand a dense softmax output layer.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.941680Z","iopub.status.idle":"2025-03-27T04:53:16.941973Z","shell.execute_reply.started":"2025-03-27T04:53:16.941818Z","shell.execute_reply":"2025-03-27T04:53:16.941829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_chrononet_model(input_shape=(4, 216), num_classes=2):\n    inputs = Input(shape=input_shape, name='input_layer')\n    conv_outputs = []\n    for k in [2, 4, 8]:\n        conv = layers.Conv1D(filters=32, kernel_size=k, strides=1, padding='same', activation='relu')(inputs)\n        conv_outputs.append(conv)\n    x = layers.Concatenate(name='concat_conv1')(conv_outputs)\n    conv_outputs = []\n    for k in [2, 4, 8]:\n        conv = layers.Conv1D(filters=32, kernel_size=k, strides=2, padding='same', activation='relu')(x)\n        conv_outputs.append(conv)\n    x = layers.Concatenate(name='concat_conv2')(conv_outputs)\n    gru1 = layers.GRU(128, return_sequences=True, name='gru1')(x)\n    gru2 = layers.GRU(128, return_sequences=False, name='gru2')(gru1)\n    x = layers.Dropout(0.5)(gru2)\n    outputs = layers.Dense(num_classes, activation='softmax', name='output')(x)\n    model = models.Model(inputs=inputs, outputs=outputs, name='ChronoNet_Model')\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nchrononet_model = build_chrononet_model(input_shape=(4,216), num_classes=2)\nchrononet_model.summary()\nplot_model(chrononet_model, to_file='chrononet_model_architecture.png', show_shapes=True, show_layer_names=True, dpi=100)\n\n# %% [markdown]\n\"\"\"\n## 5. Training the ChronoNet Model\nWe split the stacked features and one-hot labels into training and validation sets, then train the model with early stopping\nand learning rate reduction.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.942830Z","iopub.status.idle":"2025-03-27T04:53:16.943144Z","shell.execute_reply.started":"2025-03-27T04:53:16.943008Z","shell.execute_reply":"2025-03-27T04:53:16.943021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(stacked_features, labels_cat, test_size=0.2, random_state=42)\n\nearly_stopping_cb = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\nreduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n\nhistory = chrononet_model.fit(\n    X_train, y_train,\n    epochs=100,\n    batch_size=16,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stopping_cb, reduce_lr_cb]\n)\n\nchrononet_model.save('/kaggle/working/chrononet_model.h5')\n\n# %% [markdown]\n\"\"\"\n## 6. Plotting Training Metrics and Evaluation\nWe plot training/validation loss and accuracy, and generate a confusion matrix and classification report on the validation set.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.944451Z","iopub.status.idle":"2025-03-27T04:53:16.944879Z","shell.execute_reply.started":"2025-03-27T04:53:16.944648Z","shell.execute_reply":"2025-03-27T04:53:16.944666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_validation_loss(history):\n    plt.figure(figsize=(14,6))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.subplot(1,2,2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\nplot_training_validation_loss(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.946135Z","iopub.status.idle":"2025-03-27T04:53:16.946546Z","shell.execute_reply.started":"2025-03-27T04:53:16.946331Z","shell.execute_reply":"2025-03-27T04:53:16.946348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\ny_pred = chrononet_model.predict(X_val)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_true, y_pred_classes)\ncr = classification_report(y_true, y_pred_classes, target_names=['Class 0','Class 1'])\n\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0','Class 1'], yticklabels=['Class 0','Class 1'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n\nprint(\"Classification Report:\\n\", cr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T04:53:16.947514Z","iopub.status.idle":"2025-03-27T04:53:16.947801Z","shell.execute_reply.started":"2025-03-27T04:53:16.947660Z","shell.execute_reply":"2025-03-27T04:53:16.947672Z"}},"outputs":[],"execution_count":null}]}